{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Expressionism': 193,\n",
       " 'Impressionism': 1370,\n",
       " 'Surrealism': 241,\n",
       " 'Byzantine Art': 99,\n",
       " 'Post-Impressionism': 1048,\n",
       " 'Northern Renaissance': 680,\n",
       " 'Suprematism': 126,\n",
       " 'Symbolism': 171,\n",
       " 'Cubism': 439,\n",
       " 'Baroque': 586,\n",
       " 'Romanticism': 388,\n",
       " 'Mannerism': 87,\n",
       " 'Primitivism': 309,\n",
       " 'Proto Renaissance': 119,\n",
       " 'Early Renaissance': 164,\n",
       " 'High Renaissance': 301,\n",
       " 'Realism': 59,\n",
       " 'Neoplasticism': 84,\n",
       " 'Pop Art': 181,\n",
       " 'Abstract Expressionism': 24}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "artist_csv = pd.read_csv('../data/artists.csv')\n",
    "#remove artists with multiple genres\n",
    "artist_csv = artist_csv[~artist_csv[\"genre\"].str.contains(\",\")].reset_index()\n",
    "\n",
    "#find number of total paintings per genre\n",
    "dic = {}\n",
    "for g in artist_csv[\"genre\"].unique():\n",
    "   dic[g] = artist_csv[artist_csv[\"genre\"] == g][\"paintings\"].sum()\n",
    "\n",
    "dic\n",
    "# #keep only name and genre cols in df\n",
    "# artist_csv = artist_csv[[\"name\", \"genre\"]]\n",
    "# #replace spaces with underscores\n",
    "# artist_csv[\"name\"] = artist_csv[\"name\"].str.replace(\" \", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Expressionism', 'Impressionism', 'Surrealism', 'Byzantine_Art', 'Post-Impressionism', 'Northern_Renaissance', 'Suprematism', 'Symbolism', 'Cubism', 'Baroque', 'Romanticism', 'Mannerism', 'Primitivism', 'Proto_Renaissance', 'Early_Renaissance', 'High_Renaissance', 'Realism', 'Neoplasticism', 'Pop_Art', 'Abstract_Expressionism']\n"
     ]
    }
   ],
   "source": [
    "artist_csv[\"genre\"] = artist_csv[\"genre\"].str.replace(\" \", \"_\")\n",
    "genre_names = artist_csv[\"genre\"].unique().tolist()\n",
    "print(genre_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3983 images belonging to 20 classes.\n",
      "Found 984 images belonging to 20 classes.\n",
      "Total number of batches = 248 and 61\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "batch_size = 16\n",
    "train_input_shape = (224, 224, 3)\n",
    "n_classes = len(genre_names)\n",
    "\n",
    "img_dir = '../data/genre_images/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255., zoom_range=0.7)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=img_dir,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    classes=genre_names,\n",
    "                                                    target_size=train_input_shape[0:2],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    subset='training',\n",
    "                                                    shuffle=True,)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(directory=img_dir,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    classes=genre_names,\n",
    "                                                    target_size=train_input_shape[0:2],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    subset='validation',\n",
    "                                                    shuffle=True,)\n",
    "\n",
    "                                                    \n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "print(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers at the end\n",
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(512, kernel_initializer='he_uniform')(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(16, kernel_initializer='he_uniform')(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "output = Dense(n_classes, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 8\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n",
    "                           mode='auto', restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n",
    "                              verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "248/248 [==============================] - 242s 961ms/step - loss: 2.7468 - accuracy: 0.1961 - val_loss: 3.3447 - val_accuracy: 0.0840 - lr: 1.0000e-04\n",
      "Epoch 2/8\n",
      "248/248 [==============================] - 204s 821ms/step - loss: 2.6454 - accuracy: 0.2312 - val_loss: 3.0561 - val_accuracy: 0.1199 - lr: 1.0000e-04\n",
      "Epoch 3/8\n",
      "248/248 [==============================] - 202s 815ms/step - loss: 2.5634 - accuracy: 0.2657 - val_loss: 3.0050 - val_accuracy: 0.1762 - lr: 1.0000e-04\n",
      "Epoch 4/8\n",
      "248/248 [==============================] - 202s 816ms/step - loss: 2.5167 - accuracy: 0.2763 - val_loss: 2.8890 - val_accuracy: 0.2152 - lr: 1.0000e-04\n",
      "Epoch 5/8\n",
      "248/248 [==============================] - 201s 812ms/step - loss: 2.4449 - accuracy: 0.2972 - val_loss: 3.2629 - val_accuracy: 0.1824 - lr: 1.0000e-04\n",
      "Epoch 6/8\n",
      "248/248 [==============================] - 200s 805ms/step - loss: 2.4107 - accuracy: 0.3065 - val_loss: 2.7872 - val_accuracy: 0.1793 - lr: 1.0000e-04\n",
      "Epoch 7/8\n",
      "248/248 [==============================] - 199s 800ms/step - loss: 2.3788 - accuracy: 0.3123 - val_loss: 2.9437 - val_accuracy: 0.1434 - lr: 1.0000e-04\n",
      "Epoch 8/8\n",
      "248/248 [==============================] - 201s 811ms/step - loss: 2.3418 - accuracy: 0.3159 - val_loss: 2.7344 - val_accuracy: 0.1639 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3299a00>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, \n",
    "            steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "            epochs=n_epoch, \n",
    "            batch_size=batch_size,\n",
    "            validation_data=valid_generator, \n",
    "            validation_steps=STEP_SIZE_VALID, \n",
    "            callbacks=[early_stop, reduce_lr], \n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d566340f3e79cb50e4c0a92265a0920435c2c4ea639802ca116cc2a75aa6419"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
