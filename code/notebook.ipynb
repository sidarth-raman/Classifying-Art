{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.applications.resnet import ResNet50, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "artist_csv = pd.read_csv('../data/artists.csv')\n",
    "#remove artists with multiple genres\n",
    "artist_csv = artist_csv[~artist_csv[\"genre\"].str.contains(\",\")].reset_index()\n",
    "artist_csv[\"genre\"] = artist_csv[\"genre\"].str.replace(\" \", \"_\")\n",
    "\n",
    "#find number of total paintings per genre\n",
    "dic = {}\n",
    "for g in artist_csv[\"genre\"].unique():\n",
    "   dic[g] = artist_csv[artist_csv[\"genre\"] == g][\"paintings\"].sum()\n",
    "\n",
    "#keep only name and genre cols in df\n",
    "artist_csv = artist_csv[[\"name\", \"genre\", \"paintings\"]]\n",
    "#replace spaces with underscores\n",
    "artist_csv[\"name\"] = artist_csv[\"name\"].str.replace(\" \", \"_\")\n",
    "artist_csv[\"genre\"] = artist_csv[\"genre\"].str.replace(\" \", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 57.083333333333336,\n",
       " 1: 2.3378839590443685,\n",
       " 2: 13.83838383838384,\n",
       " 3: 3.120728929384966,\n",
       " 4: 8.353658536585366,\n",
       " 5: 7.098445595854923,\n",
       " 6: 4.5514950166112955,\n",
       " 7: 1.0,\n",
       " 8: 15.74712643678161,\n",
       " 9: 16.30952380952381,\n",
       " 10: 2.014705882352941,\n",
       " 11: 7.569060773480663,\n",
       " 12: 1.3072519083969465,\n",
       " 13: 4.433656957928803,\n",
       " 14: 11.512605042016807,\n",
       " 15: 23.220338983050848,\n",
       " 16: 3.5309278350515463,\n",
       " 17: 10.873015873015873,\n",
       " 18: 5.6846473029045645,\n",
       " 19: 8.011695906432749}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_csv = pd.read_csv('../data/artists.csv')\n",
    "#remove artists with multiple genres\n",
    "artist_csv = artist_csv[~artist_csv[\"genre\"].str.contains(\",\")].reset_index()\n",
    "artist_csv[\"genre\"] = artist_csv[\"genre\"].str.replace(\" \", \"_\")\n",
    "artist_csv = artist_csv[[\"name\", \"genre\", \"paintings\"]]\n",
    "artist_csv \n",
    "#transform artitst_csv to a df with columns: genre, total paintings per genre \n",
    "genre_csv = artist_csv.groupby(\"genre\").sum().reset_index()\n",
    "genre_csv[\"class_weight\"] = genre_csv[\"paintings\"].max() / genre_csv[\"paintings\"]\n",
    "genre_csv\n",
    "\n",
    "class_weights = genre_csv[\"class_weight\"].to_dict()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abstract_Expressionism',\n",
       " 'Baroque',\n",
       " 'Byzantine_Art',\n",
       " 'Cubism',\n",
       " 'Early_Renaissance',\n",
       " 'Expressionism',\n",
       " 'High_Renaissance',\n",
       " 'Impressionism',\n",
       " 'Mannerism',\n",
       " 'Neoplasticism',\n",
       " 'Northern_Renaissance',\n",
       " 'Pop_Art',\n",
       " 'Post-Impressionism',\n",
       " 'Primitivism',\n",
       " 'Proto_Renaissance',\n",
       " 'Realism',\n",
       " 'Romanticism',\n",
       " 'Suprematism',\n",
       " 'Surrealism',\n",
       " 'Symbolism']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_names = genre_csv[\"genre\"].tolist()\n",
    "genre_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3983 images belonging to 20 classes.\n",
      "Found 984 images belonging to 20 classes.\n",
      "Total number of batches = 248 and 61\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "batch_size = 16\n",
    "train_input_shape = (224, 224, 3)\n",
    "n_classes = genre_csv.shape[0]\n",
    "\n",
    "img_dir = '../data/genre_images/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   validation_split=0.2, \n",
    "                                   rescale=1./255., \n",
    "                                   shear_range=5, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=img_dir,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    classes=genre_names,\n",
    "                                                    target_size=train_input_shape[0:2],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    subset='training',\n",
    "                                                    shuffle=True,)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(directory=img_dir,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    classes=genre_names,\n",
    "                                                    target_size=train_input_shape[0:2],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    subset='validation',\n",
    "                                                    shuffle=True,)\n",
    "\n",
    "                                                    \n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "print(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers at the end\n",
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(512, kernel_initializer='he_uniform')(X)\n",
    "# X = Dropout(0.1)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = tf.keras.layers.LeakyReLU()(X)\n",
    "\n",
    "X = Dense(64, kernel_initializer='he_uniform')(X)\n",
    "# X = Dropout(0.5)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = tf.keras.layers.LeakyReLU()(X)\n",
    "\n",
    "X = Dense(16, kernel_initializer='he_uniform')(X)\n",
    "# X = Dropout(0.5)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = tf.keras.layers.LeakyReLU()(X)\n",
    "\n",
    "output = Dense(n_classes, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, \n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n",
    "                           mode='auto', restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n",
    "                              verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 355s 1s/step - loss: 2.7459 - categorical_accuracy: 0.2140 - val_loss: 2.9519 - val_categorical_accuracy: 0.1578\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 346s 1s/step - loss: 2.5198 - categorical_accuracy: 0.2972 - val_loss: 3.4078 - val_categorical_accuracy: 0.1834\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 492s 2s/step - loss: 2.4083 - categorical_accuracy: 0.3363 - val_loss: 2.7293 - val_categorical_accuracy: 0.1650\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 341s 1s/step - loss: 2.3233 - categorical_accuracy: 0.3625 - val_loss: 2.8074 - val_categorical_accuracy: 0.2490\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 355s 1s/step - loss: 2.2533 - categorical_accuracy: 0.3779 - val_loss: 2.7204 - val_categorical_accuracy: 0.2336\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 385s 2s/step - loss: 2.1981 - categorical_accuracy: 0.3907 - val_loss: 2.6165 - val_categorical_accuracy: 0.2766\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 374s 2s/step - loss: 2.1422 - categorical_accuracy: 0.4129 - val_loss: 3.3091 - val_categorical_accuracy: 0.1957\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 334s 1s/step - loss: 2.0853 - categorical_accuracy: 0.4283 - val_loss: 2.6211 - val_categorical_accuracy: 0.2254\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 341s 1s/step - loss: 2.0427 - categorical_accuracy: 0.4313 - val_loss: 2.7946 - val_categorical_accuracy: 0.1773\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 376s 2s/step - loss: 1.9935 - categorical_accuracy: 0.4401 - val_loss: 3.4011 - val_categorical_accuracy: 0.2039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c4a4940>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    batch_size=batch_size,\n",
    "    class_weight=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d566340f3e79cb50e4c0a92265a0920435c2c4ea639802ca116cc2a75aa6419"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
